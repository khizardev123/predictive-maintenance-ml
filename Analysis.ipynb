{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b23798",
   "metadata": {},
   "source": [
    "# Predictive Maintenance \n",
    "\n",
    "This notebook addresses system failure detection in a highly imbalanced dataset using class-weighted models and threshold tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7543a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "076db392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (876100, 7)\n",
      "\n",
      "Target Distribution (Original):\n",
      "failure\n",
      "0    875381\n",
      "1       719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('system_logs_ready_min.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nTarget Distribution (Original):\")\n",
    "print(df['failure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076db392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Pool Shape: 5719 (Failures: 719)\n",
      "Training set: 4575 rows | Testing set: 1144 rows\n"
     ]
    }
   ],
   "source": [
    "# Drop timestamp\n",
    "if 'timestamp' in df.columns:\n",
    "    df_clean = df.drop(columns=['timestamp'])\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "# BALANCING STRATEGY: \n",
    "# Total failures are ~719. We will sample 5,000 normal cases to maintain a strong failure signal.\n",
    "df_failures = df_clean[df_clean['failure'] == 1]\n",
    "df_normal = df_clean[df_clean['failure'] == 0]\n",
    "\n",
    "sample_normal = df_normal.sample(min(5000, len(df_normal)), random_state=42)\n",
    "df_train_pool = pd.concat([df_failures, sample_normal]).sample(frac=1, random_state=42)\n",
    "\n",
    "X = df_train_pool.drop(columns=['failure'])\n",
    "y = df_train_pool['failure']\n",
    "print(f\"Balanced Pool Shape: {len(df_train_pool)} (Failures: {len(df_failures)})\")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Stratified Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set: {len(y_train)} rows | Testing set: {len(y_test)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77429886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Training models with Balanced Class Weights\n",
    "print(\"Training models...\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Linear SVM\n",
    "svm_clf = LinearSVC(dual=False, class_weight='balanced', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fd99171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation (Default Threshold 0.5):\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Recall: 0.5972 | F1: 0.2960 | Accuracy: 0.6425\n",
      "Confusion Matrix:\n",
      " [[649 351]\n",
      " [ 58  86]]\n",
      "------------------------------\n",
      "=== Random Forest ===\n",
      "Recall: 0.0556 | F1: 0.0964 | Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      " [[986  14]\n",
      " [136   8]]\n",
      "------------------------------\n",
      "=== SVM ===\n",
      "Recall: 0.5972 | F1: 0.2966 | Accuracy: 0.6434\n",
      "Confusion Matrix:\n",
      " [[650 350]\n",
      " [ 58  86]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = {'Logistic Regression': log_reg, 'Random Forest': rf_clf, 'SVM': svm_clf}\n",
    "results = {}\n",
    "\n",
    "print(\"Model Evaluation (Default Threshold 0.5):\\n\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {'recall': recall, 'f1': f1, 'accuracy': acc}\n",
    "    \n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Recall: {recall:.4f} | F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca0dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of lowering Decision Threshold (Logistic Regression):\n",
      "Threshold: 0.5 -> Recall: 0.5972 | F1-Score: 0.2960\n",
      "Threshold: 0.4 -> Recall: 0.8056 | F1-Score: 0.2886\n",
      "Threshold: 0.3 -> Recall: 0.9167 | F1-Score: 0.2573\n",
      "Threshold: 0.2 -> Recall: 0.9792 | F1-Score: 0.2384\n",
      "Threshold: 0.1 -> Recall: 1.0000 | F1-Score: 0.2255\n"
     ]
    }
   ],
   "source": [
    "# THRESHOLD TUNING (Critical for catching failures early)\n",
    "y_scores = log_reg.decision_function(X_test)\n",
    "y_probs = 1 / (1 + np.exp(-y_scores))\n",
    "\n",
    "print(\"Effect of lowering Decision Threshold (Logistic Regression):\")\n",
    "for t in [0.5, 0.4, 0.3, 0.2, 0.1]:\n",
    "    y_pred_t = (y_probs >= t).astype(int)\n",
    "    r = recall_score(y_test, y_pred_t)\n",
    "    f = f1_score(y_test, y_pred_t)\n",
    "    print(f\"Threshold: {t:.1f} -> Recall: {r:.4f} | F1-Score: {f:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ff99c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model for Predictive Maintenance: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# Select Best Model based on Recall\n",
    "best_model_name = max(results, key=lambda x: results[x]['recall'])\n",
    "print(f\"Selected Model for Predictive Maintenance: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd46b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved. Best Model: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# Save artifacts\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(f\"Artifacts saved. Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13df5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
